#!/usr/bin/perl -w

# Podist - a podcatcher that generates playlists
# Copyright ©2008–2018  Anthony DeRobertis
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
our $PODIST_VERSION = 0.5;
our $CONFIG_VERSION = 2;

use Config::General;
use DBI;
use Digest;
use File::Copy qw(move);
use File::Find qw(find);
use File::Path qw(mkpath);
use File::Spec;
use File::Slurp qw(write_file);
use File::Temp qw(tempfile);
use Getopt::Long;
use IPC::Run3;
use List::MoreUtils qw(pairwise);
use List::Util qw(sum sum0 pairmap);
use Log::Log4perl qw(:easy :no_extra_logdie_message);
use LWP::UserAgent;
use MP3::Info qw(get_mp3info);
use Number::Format qw(format_number);
use Ogg::Vorbis::Header::PurePerl;
use Parallel::ForkManager;
use POSIX qw(strftime);
use Term::Size::Any qw(!:DEFAULT);    # need to call ->import w/o polution
use Text::ASCIITable;
use Text::CSV;
use URI::Escape qw(uri_escape);
use XML::FeedPP;
use Carp qw(longmess);
use Data::Dump qw(pp);

BEGIN { -t STDOUT and $Pod::Usage::Formatter = 'Pod::Text::Termcap'; }
use Pod::Usage;

use FindBin;
use lib "$FindBin::RealBin/lib";
use Podist::Config;
use Podist::Database;
use Podist::Misc qw(inherit_proc_profiles normalize_time);
use Podist::Processor;
use Podist::Storage;

use 5.014; # adds r flag to s///
use strict;

my ($DB, $STORAGE);    # set by setup
my $TERM_COLS;         # set by setup
my $TERM_LINES;        # set by setup
sub CONFIG();          # defined by setup
sub COMMAND();         # defined by register_commands
sub USER_AGENT();      # below

# Average year on the Gregorian calendar (in seconds), ignoring leap
# seconds (that is, presuming each day is 86,400 seconds long). This is
# 365.2425 days. Note the quoted string because this gets direct-plopped
# into SQL, and SQLite needs the .0 to do float math.
my $AVERAGE_YEAR = '31556952.0';

my %SUFFIX_MAP = (
	'audio/mpeg'        => 'mp3',    # RFC 3003
	'audio/x-mpeg'      => 'mp3',    # pre-2000
	'audio/x-mp3'       => 'mp3',    # err?
	'audio/mp3'         => 'mp3',    # umm?
	'x-audio/mp3'       => 'mp3',    # idiots
	'audio/ogg'         => 'ogg',
	'audio/x-ogg'       => 'ogg',
	'application/ogg'   => 'ogg',
	'application/x-ogg' => 'ogg',
);
my %MIME_MAP = (
	mp3  => 'audio/mpeg',
	ogg  => 'audio/ogg; codecs=vorbis',
	opus => 'audio/ogg; codecs=opus'
);

exit go(@ARGV = @ARGV); # https://rt.perl.org/Ticket/Display.html?id=131192
### functions only below ###

sub go {
	my $gopts = parse_global_opts();
	setup($gopts->{config_dir});

	# Don't do this until after setup, because we need log4perl ready
	# first!
	$SIG{__DIE__} = sub {
		if ($^S) {
			# We're in an eval {} and don't want log
			# this message but catch it later
			return;
		}
		$Log::Log4perl::caller_depth++;
		eval { LOGDIE longmess(@_) };
		FATAL("Tried to give nice error, but Carp::longmess failed. Might be Perl bug 131192. Carp blew up with:");
		FATAL("   $@");
		FATAL("First error (without backtrace) follows:");
		LOGDIE("   @_");
	};

	unless (@ARGV) {
		FATAL "You need to specify a command. Try $0 --help";
		exit 1;
	}

	register_commands();

	my $cmd = lc(shift @ARGV);
	unless (exists COMMAND->{$cmd}) {
		FATAL "Unknown command '$cmd'. Try $0 --help";
		exit 1;
	}

	TRACE("Dispatching command '$cmd'");
	COMMAND->{$cmd}(@ARGV);

	TRACE("Command done; committing");
	$DB->commit();

	return 0;
}

sub register_commands {
	*COMMAND = sub() {
		{
			add         => \&add_podcast,
			new         => \&add_podcast,
			subscribe   => \&add_podcast,

			drop        => \&drop_podcast,

			catch       => \&catch,
			fetch       => \&fetch,
			download    => \&download,
			stopwatch   => \&stopwatch,
			hash        => \&hasherize,
			hasherize   => \&hasherize,
			originalize => \&originalize,

			playlist    => \&playlist,
			archive     => \&archive,

			process     => \&process,
			feed        => \&feed,

			status      => \&status,
			history     => \&history,

			list        => \&list,
			cleanup     => \&cleanup,

			editfeed    => \&edit_podcast,
			editrandom  => \&edit_random,

			fsck        => \&fsck,
		};
	};
	TRACE("Commands registered");
}

sub add_podcast {
	my ($name, $url) = @_;

	($name//'') ne '' && ($url//'') ne ''
		or pod2usage({
			-message => "Error: Podist add/subscribe needs a name and a URL.",
			-verbose => 99,
			-sections => ['COMMAND SUMMARY'],
		});

	$DB->do(<<QUERY, {}, $name, $url);
INSERT INTO feeds(feed_name, feed_url) VALUES(?, ?)
QUERY
	my $f_no = $DB->last_insert_id('', '', 'feeds', 'feed_no');
	INFO("Added #$f_no: $name");

	return;
}

sub drop_podcast {
	my $go = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order )]);
	my $p2u = sub {
		pod2usage({
			-verbose  => 99,
			-exitval  => 2,
			-sections => [qw(SYNOPSIS COMMANDS/drop)],
			(defined $_[0] ? (-message => $_[0]) : ()),
		});
	};

	my $feed_no;
	$go->getoptions(
		'feed_no|feed-no|f=i' => \$feed_no,
	) or $p2u->();
	defined $feed_no or $p2u->();

	TRACE("Dropping feed feed_no $feed_no");
	$DB->drop_podcast($feed_no);

	return;
}

sub edit_podcast {
	my $go = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order )]);
	my $p2u = sub {
		pod2usage({
			-verbose  => 99,
			-exitval  => 2,
			-sections => [qw(SYNOPSIS COMMANDS/editfeed)],
			(defined $_[0] ? (-message => $_[0]) : ()),
		});
	};

	my %opts;
	$go->getoptions(
		\%opts, qw/
			feed_no|feed-no|f=i          url=s
			name=s enable                disable
			ordered!                     all_audio|all-audio!
			is_music|is-music!           limit_amount|limit-amount=i
			limit_period|limit-period=s  proc_profile|proc-profile=s
			/
	) or $p2u->();

	# delete returns the last removed value
	my $feed_no = delete $opts{feed_no}
		or $p2u->("Need to specify which feed to edit.");

	exists $opts{enable} and exists $opts{disable}
		and $p2u->("Can't both enable and disable a feed.");

	$opts{enabled} = 1 if delete $opts{enable};
	$opts{enabled} = 0 if delete $opts{disable};

	$opts{limit_period} = normalize_time($opts{limit_period})
		if exists $opts{limit_period};

	keys %opts
		or $p2u->("Need to specify some changes");

	%opts = pairmap { "feed_$a", $b } %opts;

	TRACE("Editing feed #$feed_no, changes: @{[ pp \%opts ]}");
	$DB->update_feed($feed_no, \%opts);

	return;
}

sub edit_random {
	my $go = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order )]);
	my $p2u = sub {
		pod2usage({
			-verbose  => 99,
			-exitval  => 2,
			-sections => [qw(SYNOPSIS COMMANDS/editrandom)],
			(defined $_[0] ? (-message => $_[0]) : ()),
		});
	};

	my %opts;
	$go->getoptions(
		\%opts, qw/random_no|random-no|r=i weight=i name=s/
	) or $p2u->();

	# delete returns the last removed value
	my $random_no = delete $opts{random_no}
		or $p2u->("Need to specify which random to edit.");

	exists $opts{weight} and $opts{weight} < 0
		and $p2u->("Random weight must be non-negative.");

	keys %opts
		or $p2u->("Need to specify some changes.");

	%opts = pairmap { "random_$a", $b } %opts;

	TRACE("Editing random #$random_no, changes: @{[ pp \%opts ]}");
	$DB->update_random($random_no, \%opts);

	return;
}

sub catch {
	fetch();
	download();
	stopwatch();
	hasherize();
	originalize();
}

sub fetch {
	my $go = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order )]);

	my (@only_feeds, $override_fetch_limit);
	$go->getoptions(
		'feeds|f=i{1,}' => \@only_feeds,
		'new-limit|limit|fetch-limit|l=i' => \$override_fetch_limit
	) or pod2usage(2);

	my $sth_feeds;
	if (@only_feeds) {
		TRACE("Grabbing specified feed @{[join q{,}, @only_feeds]} from DB");
		$sth_feeds = $DB->prepare(<<QUERY);
SELECT
    feed_no, feed_name, feed_url, feed_all_audio,
    feed_limit_amount, feed_limit_period
  FROM feeds
  WHERE feed_no IN (@{[join q{,}, @only_feeds]})
  ORDER BY feed_no
QUERY
	} else {
		TRACE("Finding enabled feeds in db");
		$sth_feeds = $DB->prepare(<<QUERY);
SELECT
    feed_no, feed_name, feed_url, feed_all_audio,
    feed_limit_amount, feed_limit_period
  FROM feeds
  WHERE feed_enabled = 1
  ORDER BY feed_no
QUERY
	}
	$sth_feeds->execute;

	my $sth_used = $DB->prepare(<<QUERY);
SELECT COUNT(*)
  FROM fetches f JOIN articles a ON (f.fetch_no = a.fetch_no)
  WHERE a.article_use = 1 AND f.feed_no = ? AND f.fetch_when >= ?
QUERY

	FEED: while (my ($feed_no, $feed_name, $feed_url, $all_audio, $limit_amount, $limit_period)
		= $sth_feeds->fetchrow_array)
	{
		$sth_used->execute($feed_no, time-$limit_period);
		my ($limit_used) = $sth_used->fetchrow_array;
		$sth_used->finish;

		my $limit_remain = $override_fetch_limit
			// ($limit_amount - $limit_used);
		if ($limit_remain <= 0) {
			WARN("Skipping $feed_name (#$feed_no) because limit fully used.");
			next;
		}

		my $fetch_no = $DB->add_fetch($feed_no);
		INFO("Fetching $feed_name (feed#$feed_no, fetch#$fetch_no, limit=$limit_remain)");
		$DB->do("SAVEPOINT one_fetch");
		my $resp = USER_AGENT->get($feed_url);
		unless ($resp->is_success) {
			ERROR("Downloading of $feed_name from $feed_url failed:");
			ERROR($resp->status_line);
			$DB->finish_fetch($fetch_no, 'http_error');

			next; # ignore this feed
		}

		my $content_type = $resp->content_type;
		TRACE("Content-Type: $content_type");
		$content_type =~ m#^(application/((rss|atom|rdf)\+)?xml)|(text/xml)$ #x
			or WARN("Unexpected MIME type $content_type; bad things may happen");

		TRACE("Handing over to the feed parser");
		my $feed = eval {
			# workaround bug 661551
			my $content = $resp->decoded_content;
			$content =~ s/^\x{FEFF}//;
			XML::FeedPP->new($content, type => 'string');
		};
		if ($@) {
			ERROR("Feed parse exploded: $@");
			$DB->finish_fetch($fetch_no, 'parse_error');
			next;
		}
		unless ($feed) {
			ERROR("Feed parser failed.");
			next;
		}

		my ($date_last1, $date_last2);
		my $item_count = 0;
		ITEM: foreach my $item ($feed->get_item) {
			my $enc_url = $item->get('enclosure@url');
			(my $item_title = $item->title) =~ y/\x0a\x0d/ /;
			$item_title =~ s/^\s+//;
			$item_title =~ s/\s+$//;

			unless ($enc_url) {
				my $msg = "Item $item_title has no enclosure";
				$all_audio ? INFO($msg) : TRACE($msg);
				next;
			}

			my $enc_type = $item->get('enclosure@type');
			unless (!defined $enc_type || '' eq $enc_type || $enc_type =~ m#^(audio|x-audio|application)/(ogg|x-ogg|mpeg|x-mpeg|x-mp3|mp3)$ #x) {
				my $msg = "Skipping $item_title (uknown enclosure type $enc_type)";
				$all_audio ? WARN($msg) : TRACE($msg);
				next;
			}

			my $date = $item->get_pubDate_epoch;

			# KLUGE: fails if the date has spaces; work around...
			if (!$date && '' ne $item->get_pubDate_native) {
				TRACE("Space-normalizing date");
				$date = $item->get_pubDate_native;
				$date =~ s/^\s+//;
				$date =~ s/\s+$//;
				$date =~ s/\s+/ /g;
				$item->pubDate($date);
				$date = $item->get_pubDate_epoch;
			}

			if (!$date) {
				ERROR("@{[ $item->title ]}: get_pubDate_epoch failed");
				if (defined $date_last2) {
					if ($date_last2 > $date_last1) {
						# podcast is most-recent first
						WARN("Assuming one second BEFORE previous");
						$date = $date_last1 - 1;
					} elsif ($date_last2 < $date_last1) {
						# podcast is least-recent first
						WARN("Assuming one second AFTER previous");
						$date = $date_last1 + 1;
					} else {
						WARN("Assuming same date as previous two!");
						$date = $date_last1;
					}
				} elsif (defined $date_last1) {
					# randomly guess podcast is most-recent first; a lot
					# seem to be.
					WARN("Guessing most-recent first");
					WARN("Guessing one second BEFORE previous");
					$date = $date_last1 - 1;
				} else {
					WARN("Is first item; no f—ing clue what date to use");
					WARN("Using current time!");
					$date = time;
				}
				DEBUG("The time is now "
						. strftime("%F %H:%M:%S %Z", localtime($date))
						. ".\nDo you know where your podcasts are?");
			}

			my $article_no;
			my $article_uid = $item->guid;

			# parser fails to perform XML whitespace normalization...
			$article_uid =~ s/^\s+//;
			$article_uid =~ s/\s+$//;
			$article_uid =~ s/\s+/ /g;

			if (defined $article_uid && '' eq $article_uid) {
				TRACE("Ignoring blank guid");
				$article_uid = undef;    # thank you Stack Overflow Blog.
			}
			if (defined $article_uid) {
				$article_no = $DB->find_article(uid => $article_uid);
				TRACE("Checked for uid $article_uid in DB.");
			} else {
				$article_no
					= $DB->find_article(when => $date, title => $item_title);
				TRACE("Checked for title $item_title date $date in DB.");
			}
			if ($article_no) {
				TRACE("Skipping already-in-db article.");
				next;
			}

			my $article_use = 1;
			if ($item_title =~ CONFIG->{article}{titleignorere}) {
				INFO("Will set don't-use on title-ignored $item_title.");
				$article_use = 0;
			}

			$article_no = $DB->add_article(
				feed  => $feed_no,
				fetch => $fetch_no,
				use   => $article_use,
				uid   => $article_uid,
				title => $item_title,
				when  => $date
			);
			DEBUG("Added article $article_no to DB for \"$item_title\"");

			if ($article_use) {
				++$item_count;
				if ($item_count > $limit_remain) {
					ERROR("Feed $feed_name (#$feed_no) exceeded new article limit ($limit_remain). Rolling back.");
					$DB->do(q{ROLLBACK TO SAVEPOINT one_fetch});
					$DB->finish_fetch($fetch_no, 'Limit');
					next FEED;
				}
				my $enclosure_no = $DB->find_enclosure($enc_url);
				if (!$enclosure_no) {
					$enclosure_no = $DB->add_enclosure($enc_url);
					DEBUG(qq{Added enclosure $enclosure_no for "$enc_url".});
				}
				$DB->link_article_enclosure($article_no, $enclosure_no);
				TRACE("Linked enclosure $enclosure_no to article $article_no");
			}

			$date_last2 = $date_last1;
			$date_last1 = $date;
		}

		# we got here, so it's OK.
		$DB->finish_fetch($fetch_no, 'OK');
		$DB->do(q{RELEASE SAVEPOINT one_fetch});
	}
}

sub download {
	# We sort by URL in hopes of maximizing use of persistent
	# connections (HTTP Keepalive). Next sort by the number to make this
	# deterministic.
	TRACE("Finding undownloaded media");
	my $sth = $DB->prepare(<<QUERY);
SELECT DISTINCT e.enclosure_no, e.enclosure_url
  FROM enclosures e
  JOIN articles_enclosures ae ON (e.enclosure_no = ae.enclosure_no)
  JOIN articles a ON (ae.article_no = a.article_no)
  WHERE e.enclosure_file IS NULL
    AND e.enclosure_use = 1
    AND a.article_use = 1
  ORDER BY e.enclosure_url, e.enclosure_no
QUERY
	$sth->execute;

	while (my ($enc_no, $enc_url) = $sth->fetchrow_array) {
		INFO("Downloading $enc_url");
		my $tmp = $STORAGE->new_dl_temp();
		my $resp = USER_AGENT->get( $enc_url, ':content_file' => $tmp);
		unless ($resp->is_success) {
			ERROR("Downloading $enc_url failed:");
			ERROR($resp->status_line);
			$STORAGE->discard_dl_temp($tmp);
			next;
		}

		my $exp_len = $resp->header('Content-Length');
		my $act_len = -s $tmp;
		if (defined $exp_len && $exp_len != $act_len) {
			# Thank you, Virginia Foundation for the Humanities.
			ERROR("Download truncated; expected $exp_len but got $act_len");
			ERROR("Run Podist download to try this one again");
			$STORAGE->discard_dl_temp($tmp);
			next;
		}

		my $name = $resp->filename;
		DEBUG("Server's name: $name");

		# Sanitize
		$name =~ tr/-_.a-zA-Z0-9//cd;

		# Figure filename suffix
		my $ctype = lc $resp->content_type;
		my $suffix;
		if (exists $SUFFIX_MAP{$ctype}) {
			$suffix = $SUFFIX_MAP{$ctype};
		} elsif ($name =~ /\.(mp3|ogg)$/) {
			if ('text/plain' eq $ctype) {
				$suffix = $1;
				WARN("Server broken; $enc_url gave us text/plain for $suffix");
			} elsif (-1 == index($ctype, '/')) {
				# seems podcastdownload.npr.org often gives a date(!) in
				# the content-type header. WTF. Confirmed with
				# Wireshark. But its only sometimes...
				$suffix = $1;
				WARN("Server broken; $enc_url gave WTF $ctype for $suffix");
			} else {
				$suffix = 'wtf';
				ERROR("Got $ctype for $suffix at $enc_url; will not use...");
			}
		} else {
			$suffix = 'wtf';
		}

		DEBUG("Content-Type: $ctype; suffix: $suffix");

		$name =~ /\.$suffix$/
			or $name .= ".$suffix";

		# Prefix enclosure number, guaranteeing uniqueness.
		$name = sprintf("%04i_%s", $enc_no, $name);

		# Rename
		DEBUG("Renaming to: $name");
		$STORAGE->save_dl_temp(
			temp         => $tmp,
			new_name     => $name,
			enclosure_no => $enc_no
		);
	}
}

sub status {
	# 31,556,952 seconds = 1 (average) year on Gregorian calendar,
	# presuming 86400 seconds/day.
	my $tab = Text::ASCIITable->new({
			outputWidth => 72,
			headingText => 'Current Feed Status'
	});
	$tab->setCols('Feed', 'Casts', 'Hours', '%Dwnld', '%Plst', 'Upl', 'Oldest');
	$tab->addRow(@$_[1..7]) foreach @{$DB->selectall_arrayref(<<QUERY)};
SELECT
	feed_enabled,
    feed_name,
    COUNT(e.enclosure_no),
    ROUND(SUM(e.enclosure_time)/3600),
    SUM(CASE WHEN e.enclosure_file IS NULL THEN 0 ELSE 100 END)/COUNT(*),
    SUM(CASE WHEN e.playlist_no IS NULL THEN 0 ELSE 100 END)/COUNT(*) AS pct,
    SUM(CASE WHEN e.playlist_no IS NULL THEN 1 ELSE 0 END) AS cnt,
    CASE SUM(CASE WHEN e.playlist_no IS NULL THEN 1 ELSE 0 END)
      WHEN 0 THEN ''
      ELSE PRINTF('%0.2f', (STRFTIME('%s', 'now') - MIN(CASE WHEN e.playlist_no IS NULL THEN a.article_when ELSE null END))/$AVERAGE_YEAR)
    END
  FROM
    feeds f
    LEFT JOIN articles a ON (f.feed_no = a.feed_no)
    LEFT JOIN articles_enclosures ae ON (a.article_no = ae.article_no)
    LEFT JOIN enclosures e ON (ae.enclosure_no = e.enclosure_no)
  WHERE
    COALESCE(e.enclosure_use,1) = 1 -- COALESCE due to LEFT JOIN
    AND COALESCE(a.article_use,1) = 1 -- COALESCE due to LEFT JOIN
  GROUP BY feed_name
  HAVING
    f.feed_enabled = 1 OR cnt > 0
  ORDER BY CASE cnt WHEN 0 THEN 1 ELSE 0 END, LOWER(feed_name)
QUERY
	print $tab, "\n";

	$tab = Text::ASCIITable->new({
			outputWidth => 72,
			headingText => 'Overall Summary by Playlisted Status'
	});
	$tab->setCols('Status', 'Casts', 'Hours', 'Days', 'Years', 'Oldest');
	my $summaries = $DB->selectall_arrayref(<<QUERY);
SELECT
    CASE WHEN ue.playlist_no IS NULL THEN
      'Pending'
    ELSE
      CASE WHEN p.playlist_archived IS NULL THEN
        'Playlisted'
      ELSE
        'Archived'
      END
    END AS status,
    COUNT(ue.enclosure_no),
    SUM(ue.enclosure_time),
    MIN(ue.earliest_article_when)
  FROM
    usable_enclosures ue
    LEFT JOIN playlists p ON (ue.playlist_no = p.playlist_no )
  GROUP BY status
  ORDER BY
    CASE status
      WHEN 'Playlisted' THEN 1
      WHEN 'Pending' THEN 2
      WHEN 'Archived' THEN 3
      ELSE 4
    END ASC
QUERY
	my @total = ('TOTAL');
	my $sum_add_row = sub {
		my $summary = shift;
		$tab->addRow(
			$summary->[0],
			format_number($summary->[1],                 0, 0),
			format_number($summary->[2] / 3600,          0, 0),
			format_number($summary->[2] / 86400,         1, 1),
			format_number($summary->[2] / $AVERAGE_YEAR, 2, 1),
			defined $summary->[3]
				? strftime('%Y-%m-%d %H:%M:%S %Z', localtime $summary->[3])
				: ''
		);
	};
	foreach my $summary (@$summaries) {
		$sum_add_row->($summary);
		# col 0 is name, final is timestamp: ignore both.
		for (my $i = 1; $i < $#$summary; ++$i) {
			$total[$i] += $summary->[$i];
		}
	}
	$tab->addRowLine;
	$sum_add_row->(\@total);
	print $tab, "\n";
	$sum_add_row = undef;

	$tab = Text::ASCIITable->new({
			outputWidth => 72,
			headingText => 'New Hours per Day over Various Time Periods'
	});
	$tab->setCols(qw(Feed 2d 7d 30d 90d 4ever Life));
	$tab->alignCol($_, 'right') foreach(qw(2d 30d 90d 4ever Life));
	my $sth = $DB->prepare(<<QUERY);
WITH
  feed_unique_enclosures AS (
    SELECT
        a.feed_no, e.enclosure_no, MIN(a.article_when) as first_when
      FROM
        articles a
        JOIN articles_enclosures ae ON (a.article_no = ae.article_no)
        JOIN enclosures e ON (ae.enclosure_no = e.enclosure_no)
      WHERE
        a.article_use = 1 AND e.enclosure_use = 1
      GROUP BY a.feed_no, e.enclosure_no
  )
SELECT
    f.feed_enabled,
    CASE WHEN f.feed_enabled = 0 THEN 'OFF - ' ELSE '' END || f.feed_name,
    SUM(
      CASE WHEN fue.first_when + 2*86400 >= 0+strftime('%s', 'now')
        THEN e.enclosure_time
        ELSE 0
      END)/(2*3600) AS "48h",
    SUM(
      CASE WHEN fue.first_when + 7*86400 >= 0+strftime('%s', 'now')
        THEN e.enclosure_time
        ELSE 0
      END)/(7*3600) AS "168h",
    SUM(
      CASE WHEN fue.first_when + 30*86400 >= 0+strftime('%s', 'now')
        THEN e.enclosure_time
        ELSE 0
      END)/(30*3600) AS "720h",
    SUM(
      CASE WHEN fue.first_when + 90*86400 >= 0+strftime('%s', 'now')
        THEN e.enclosure_time
        ELSE 0
      END)/(90*3600) AS "2160h",
    CASE WHEN f.feed_enabled = 1 THEN
      SUM(
        e.enclosure_time
      )/((
        strftime('%s')-MIN(fue.first_when)
      )/24)
    ELSE 0
    END AS "4ever",
    CASE WHEN f.feed_enabled = 1 THEN
      SUM(
        e.enclosure_time
      )/((
        MAX(fue.first_when)-MIN(fue.first_when)
      )/24)
    ELSE 0
    END AS "Life"
  FROM
    feeds f
    LEFT JOIN feed_unique_enclosures fue ON (f.feed_no = fue.feed_no)
    LEFT JOIN enclosures e ON (fue.enclosure_no = e.enclosure_no)
  GROUP BY f.feed_no
  HAVING
    f.feed_enabled = 1
    OR "48h" > 0
    OR "168h" > 0
    OR "720h" > 0
    OR "2160h" > 0
  ORDER BY
    f.feed_enabled DESC,
    CASE WHEN "48h" > 0 THEN 0 ELSE 1 END,
    CASE WHEN "168h" > 0 THEN 0 ELSE 1 END,
    CASE WHEN "720h" > 0 THEN 0 ELSE 1 END,
    CASE WHEN "2160h" > 0 THEN 0 ELSE 1 END,
    f.feed_name
QUERY
	$sth->execute;
	@total = (0)x($sth->{NUM_OF_FIELDS}-2);
	while (my (undef, $n, @times) = $sth->fetchrow_array) {
		pairwise { our ($a, $b); $a += ($b // 0) } @total, @times;
		$tab->addRow($n, map format_perday($_), @times);
	}
	$tab->addRowLine;
	$tab->addRow('TOTAL', map format_perday($_), @total);
	$tab->addRow('', map sprintf("%im", $_*60), @total);
	print $tab;
}

sub history {
	local $_;
	my $csv = Text::CSV->new({
			always_quote => 0,
			quote_space  => 0,
			auto_diag    => 2,
			eol          => $/,
		}) or LOGCONFESS("New Text::CSV failed.");

	my $sth = $DB->prepare(<<QUERY);
SELECT
    DATETIME(times.t, 'unixepoch') AS When_UTC,
    COUNT(DISTINCT ue.enclosure_no) AS N_tot,
    SUM(CASE WHEN p.playlist_ctime <= times.t
        THEN 0 ELSE 1 END) AS N_unpl,
    SUM(ue.enclosure_time) AS T_tot,
    SUM(CASE WHEN p.playlist_ctime <= times.t
        THEN 0 ELSE ue.enclosure_time END) AS T_unpl
  FROM
    (SELECT DISTINCT playlist_ctime AS t FROM playlists) AS times
    INNER JOIN usable_enclosures ue
    LEFT JOIN playlists p ON (ue.playlist_no = p.playlist_no)
  WHERE ue.earliest_article_when <= times.t
  GROUP BY times.t
  ORDER BY times.t
QUERY
	TRACE("Running (long) history query.");
	$csv->print(\*STDOUT, $sth->{NAME});
	$sth->execute;
	$csv->print(\*STDOUT, $_) while defined ($_ = $sth->fetchrow_arrayref);
	$sth->finish;
}

sub list {
	my $go = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order )]);

	my %opts;
	$go->getoptions(\%opts, qw(feeds|f randoms|r long|l) ) or pod2usage(2);
	keys %opts or pod2usage("Need to specify something to list.");

	if ($opts{feeds}) {
		my @header = ('Enabled', 'Feed Name', 'Feed #', 'Proc.');
		my @cols = (
			q{CASE WHEN feed_enabled THEN 'Yes' ELSE 'No' END},
			q{feed_name},
			q{feed_no},
			q{feed_proc_profile},
		);
		if ($opts{long}) {
			# --long is probably doable on a 132-wide term, but right
			# now Text::ASCITable can't properly wrap URLs. So use a
			# very wide xterm or less -S.

			push @header, qw(URL Ordered All-Audio Music Limit Period);
			push @cols, (
				q{feed_url},
				q{CASE WHEN feed_ordered THEN 'Yes' ELSE 'No' END},
				q{CASE WHEN feed_all_audio THEN 'Yes' ELSE 'No' END},
				q{CASE WHEN feed_is_music THEN 'Yes' ELSE 'No' END},
				q{feed_limit_amount},
				q{feed_limit_period},
			);
		}
		my $tab = Text::ASCIITable->new({
				outputWidth => $TERM_COLS,
				headingText => 'Feeds'
		});
		$tab->setCols(@header);
		$tab->addRow(@$_) foreach @{$DB->selectall_arrayref(<<QUERY)};
SELECT
    ${ \join(qq{,\n    }, @cols) }
  FROM feeds
  ORDER BY feed_enabled DESC, feed_name ASC
QUERY
		say $tab;
	}

	if ($opts{randoms}) {
		my $randoms = find_random_items();
		my $tab = Text::ASCIITable->new({
				outputWidth => $TERM_COLS,
				headingText => 'Random Items'
		});
		$tab->setCols('DB', 'File', 'Name', 'Weight', 'As %');
		my $longwidth = int(($TERM_COLS-32) / 2);
		$longwidth = 20 if $longwidth < 20;
		$tab->setColWidth('File', $longwidth);
		$tab->setColWidth('Name', $longwidth);
		foreach my $random (
			sort({ $::a->{random_file} cmp $::b->{random_file} }
				@{$randoms->{randoms}}),
			sort({ $::a->{random_file} cmp $::b->{random_file} }
				@{$randoms->{disabled}}))
		{
			$tab->addRow(
				$random->{random_no},
				$random->{random_file},
				$random->{random_name},
				$random->{random_weight},
				sprintf('%.3f',
					100 * $random->{random_weight} / $randoms->{total_weight}));
		}

		say $tab;
	}
}

sub format_perday {
	defined $_[0]
		or return 'N/A';
	my $r = sprintf('%04.2f', $_[0]);
	'0.00' eq $r ? $_[0] == 0 ? '' : 'T' : $r;
}

sub fsck {
	my $problems = 0;

	TRACE('Looking for orphaned enclosures.');
	my $sth = $DB->prepare(<<QUERY);
SELECT e.enclosure_no, e.enclosure_url
  FROM enclosures e
  WHERE
    e.enclosure_use = 1
    AND NOT EXISTS (
      SELECT 1
      FROM articles_enclosures ae
      WHERE ae.enclosure_no = e.enclosure_no
    )
QUERY
	$sth->execute;
	while (my ($eno, $eurl) = $sth->fetchrow_array) {
		++$problems;
		ERROR("Enclosure number $eno downloaded from $eurl is orphaned.");
	}
	$sth->finish;

	TRACE(q{Looking for don't use yet on playlist});
	$sth = $DB->prepare(<<QUERY);
SELECT e.enclosure_no, e.playlist_no
  FROM enclosures e
  WHERE
    e.enclosure_use = 0
    AND e.playlist_no IS NOT NULL
QUERY
	$sth->execute;
	while (my ($eno, $pno) = $sth->fetchrow_array) {
		++$problems;
		ERROR("Enclosure number $eno is set use=0 but is on playlist $pno.");
	}
	$sth->finish;

	$problems += $STORAGE->fsck;

	if ($problems) {
		ERROR("Number of problems remaining after fsck: $problems.");
	} else {
		INFO("No problems remain after fsck.");
	}
	return !$problems;
}

sub cleanup {
	fsck() || LOGDIE("fsck found problems - aborting cleanup");

	hasherize(); # make sure we have the hash before moving the file

	my $sth = $DB->prepare(<<QUERY);
SELECT enclosure_no
  FROM enclosures
  WHERE
    enclosure_use = 0
    AND enclosure_store = 'pending'
    AND playlist_no IS NULL
    AND enclosure_file IS NOT NULL
QUERY

 	TRACE("Finding enclosure_use=0 media in db");
 	$sth->execute;

	INFO("Moving unusable files, this may take a while");
 	my $moved = 0;
	while (my ($e_no) = $sth->fetchrow_array) {
		TRACE("Moving enclosure $e_no");
		$STORAGE->unusable_pending($e_no);
		++$moved;
	}

	INFO("Moved $moved files to UnusableMedia");

	INFO("Vacuuming database");
	$DB->vacuum();
	INFO("Database vacuumed.");
}

sub hasherize {
	# TODO: Would benefit from a Storage iterator that'd also give the
	#       path in one go. (See also stopwatch)
	my $sth = $DB->prepare(<<QUERY);
SELECT enclosure_no
  FROM enclosures
  WHERE
    enclosure_file IS NOT NULL
    AND enclosure_hash IS NULL
QUERY

	my $upd = $DB->prepare(<<QUERY);
UPDATE enclosures
  SET enclosure_hash = ?
  WHERE enclosure_no = ?
QUERY

	TRACE("Finding media without hash in db");
	$sth->execute;

	my $ctx = Digest->new('SHA-256')
		or LOGDIE("Couldn't get SHA-256 digest");
	while (my ($enc_no) = $sth->fetchrow_array) {
		my $file = $STORAGE->get_enclosure_path($enc_no);

		$ctx->reset;
		if (open my $fh, '<:raw', $file) {
			$ctx->addfile($fh);
			close $fh or LOGDIE("Close on $file failed: $!");
		} else {
			ERROR("Could not open $file: $!");
			next;
		}
		my $hash = 'sha256:' . $ctx->b64digest;

		TRACE("$file: $hash");
		$upd->execute($hash, $enc_no);
	}
}

sub originalize {
	TRACE("Marking duplicates as don't use.");
	my $dups = $DB->selectall_arrayref(<<QUERY);
SELECT DISTINCT
    e2.enclosure_no, e2.enclosure_file
  FROM
    enclosures e1 JOIN enclosures e2 ON (
      e1.enclosure_hash = e2.enclosure_hash
    )
  WHERE
    e1.enclosure_no < e2.enclosure_no
    AND e1.enclosure_use = 1 AND e2.enclosure_use = 1
    AND e2.playlist_no IS NULL
QUERY

	my $mark = $DB->prepare(<<QUERY);
UPDATE enclosures SET enclosure_use = 0 WHERE enclosure_no = ?
QUERY
	foreach my $dup (@$dups) {
		INFO("Duplicate: $dup->[1]; setting enclosure_use=0");
		$mark->execute($dup->[0]);
	}
}

sub stopwatch {
	# TODO: Someday make storage provide an iterator that'd combine this
	#       select w/ getting the path. (See also hasherize)
	my $sth = $DB->prepare(<<QUERY);
SELECT enclosure_no
  FROM enclosures
  WHERE
    enclosure_file IS NOT NULL
    AND enclosure_time IS NULL
    AND enclosure_use = 1
QUERY

	my $upd = $DB->prepare(<<QUERY);
UPDATE enclosures
  SET enclosure_time = ?
  WHERE enclosure_no = ?
QUERY

	TRACE("Finding media without length in db");
	$sth->execute;

	while (my ($enc_no) = $sth->fetchrow_array) {
		my $file = $STORAGE->get_enclosure_path($enc_no);
		my $len = get_file_duration($file);

		defined $len or next;

		0 == $len
			and WARN("Got length of 0 for $file; probably wrong!");

		DEBUG("$file: $len");
		$upd->execute($len, $enc_no);
	}
}

sub get_file_duration {
	my $file = shift;

	unless ($file =~ /\.(.{3})$/) {
		ERROR("Could not find suffix in $file");
		ERROR("This shouldn't happen, as we always set a suffix. WTF.");
		next;
	}
	if ($1 eq 'mp3') {
		my $inf = get_mp3info($file);
		if ($inf) {
			return $inf->{SECS};
		} else {
			WARN("Could not get length of $file");
			return;
		}
	} elsif ($1 eq 'ogg') {
		my $ogg = Ogg::Vorbis::Header::PurePerl->new($file);
		if ($ogg) {
			return $ogg->info('length');
		} else {
			WARN("Ogg parser doesn't think $file is ogg");
			return;
		}
	} else { # ffprobe does basically everything
		my $stdout;
		run3([
				qw(ffprobe -of default=nk=1:nw=1 -loglevel error -hide_banner
					-show_entries format=duration),
				$file
			],
			\undef, \$stdout, undef
		);
		if (0 != $?) {
			WARN("ffprobe of $file failed: $?");
			return;
		}
		return 0 + $stdout;
	}
}

sub playlist {
	my $p_no
		= $DB->add_playlist('Playlist %03i.m3u');    # TODO: should be conf

	my $randoms = find_random_items();
	my @playlist = ();
	my @bans;
	my $duration = 0;
	my $last_feed = 0; # feed_no's start at 1, avoid undef warnings
	my $consec = 0;
	my %feed_cnts;;
	my $since_rand_itms = 0;
	my $since_rand_time = 0;
	my $random_m = CONFIG->{playlist}{randomchancem};
	my $random_b = CONFIG->{playlist}{randomchanceb};
	my $random_mode = lc(CONFIG->{playlist}{randomchancemode});

	if (CONFIG->{playlist}{announcebegin}) {
		push @playlist, [announce('begin', $p_no, 1, {
			current => $p_no,
			next => 1+$p_no,
		}), undef];
	}

	# TODO: FIXME; need storage manager support for this
	my $mark = $DB->prepare(<<QUERY);
UPDATE enclosures
  SET playlist_no = ?, playlist_so = ?, enclosure_store = 'original'
  WHERE enclosure_no = ?
QUERY

	my $note_intermission = $DB->prepare(<<QUERY);
INSERT INTO random_uses(
    random_no, random_use_reason, playlist_no, playlist_so
  )
    VALUES (?, 'intermission', ?, ?)
QUERY
	my $note_leadout = $DB->prepare(<<QUERY);
INSERT INTO random_uses(
    random_no, random_use_reason, playlist_no, playlist_so
  )
    VALUES (?, 'lead-out', ?, ?)
QUERY

	until ($duration >= CONFIG->{playlist}{targetduration}
			|| @playlist >= CONFIG->{playlist}{maximumfiles})
	{
		my $only_feed = '1';
		my $order;
		my $where = playlist_valid_where(scalar @playlist,
			$duration, $last_feed, $consec, \@bans);
		TRACE("Rules-enforcing WHERE: $where");

		# Figure the choice method
		if (CONFIG->{playlist}{choicemethod} =~ /RandomFeed/i) {
			($only_feed) = $DB->selectrow_array(<<QUERY);
SELECT DISTINCT feed_no FROM valids
  WHERE $where
  ORDER BY random() LIMIT 1
QUERY
			$order = 'random()';
			$only_feed
				or last;
			TRACE("Picked feed $only_feed");
			$only_feed = "feed_no = $only_feed";
		} else {
			my $method = lc(CONFIG->{playlist}{choicemethod});
			if    ($method eq 'random')  { $order = 'random()' }
			elsif ($method eq 'longest') { $order = 'enclosure_time DESC' }
			elsif ($method eq 'oldest')  { $order = 'enclosure_when ASC' }
			else                         { LOGIDE("Unknown ChoiceMethod: $_") }
		}
		TRACE("ORDER BY $order");

		# Chose an item.
		my ($feed_no, $enc_no, $enc_time)
			= $DB->selectrow_array(<<QUERY);
SELECT feed_no, enclosure_no, enclosure_time
  FROM valids
  WHERE ($where) AND ($only_feed)
  ORDER BY $order
  LIMIT 1
QUERY
		$enc_no
			or last;
		DEBUG("Picked feed $feed_no, enc $enc_no, dur $enc_time");

		my $old_path = $STORAGE->get_enclosure_path($enc_no);
		$mark->execute($p_no, 1+@playlist, $enc_no);
		my $new_path = $STORAGE->get_enclosure_path($enc_no);
		TRACE("Enclosure path change: $old_path -> $new_path");
		push @playlist, [$new_path, $old_path];
		$duration += $enc_time;

		if ($feed_no == $last_feed) {
			++$consec;
		} else {
			$last_feed = $feed_no;
			$consec = 1;
		}

		if (++$feed_cnts{$feed_no} >= CONFIG->{playlist}{maximumperfeed}) {
			push @bans, $feed_no;
		}

		# Update random stats
		++$since_rand_itms;
		$since_rand_time += $enc_time;

		# Randomly add a random item, maybe.
		my $add_random = 0;
		my $x
			= ('time' eq $random_mode) ? $since_rand_time : $since_rand_itms;
		my $chance = $x * $random_m + $random_b;
		TRACE("Random chance = $chance");
		if (rand() < $chance) {
			my $item = get_one_random(
				randoms  => $randoms,
				mark     => $mark,
				note     => $note_intermission,
				playlist => $p_no,
				position => (1 + @playlist),
			);
			DEBUG("Adding random item $item->[0]");
			push @playlist, $item;

			$since_rand_time = 0;
			$since_rand_itms = 0;

			if (CONFIG->{playlist}{resetconsecutive}) {
				$consec = 0;
				$last_feed = 0;
			}
		}


		DEBUG("Playlist files=" . scalar(@playlist) . "; dur=$duration");
	}

	TRACE("Done with playlist add loop - doing constraint checks");
	$duration < CONFIG->{playlist}{minimumduration}
		and LOGDIE("Playlist too short; abort");
	@playlist < CONFIG->{playlist}{minimumfiles}
		and LOGDIE("Playlist has too few files; abort");

	if ((my $ll = CONFIG->{playlist}{leadoutlength}) > 0) {
		if (CONFIG->{playlist}{announceleadout}) {
			push @playlist, [announce('leadout', $p_no, 1+@playlist, {
				current => $p_no,
				next => 1+$p_no,
			}), undef];
		}

		for (1..$ll) {
			my $item = get_one_random(
				randoms  => $randoms,
				note     => $note_leadout,
				playlist => $p_no,
				position => (1 + @playlist),
			);
			DEBUG("Adding leadout item $item->[0]");
			push @playlist, $item;
		}
	}

	if (CONFIG->{playlist}{announceend}) {
		push @playlist, [announce('end', $p_no, 1+@playlist , {
			current => $p_no,
			next => 1+$p_no,
		}), undef];
	}

	my $fname = $STORAGE->get_playlist_path($p_no);
	DEBUG("Writing playlist $fname");

	write_file(
		$fname,
		map(File::Spec->abs2rel($_->[0], CONFIG->{storage}{playlists}) . "\n",
			@playlist));

	# TODO: FIXME: Storage manager needs playlist building support to
	#              build all this then commit it at the end.
	TRACE("Moving files");
	foreach my $item (@playlist) {
		next unless defined $item->[1]; # only if had old name

		# FIXME: this is evil...
		my (undef, $dir, undef) = File::Spec->splitpath($item->[0]);
		-d $dir || mkdir $dir or LOGDIE("mkdir($dir): $!");
		$STORAGE->_safe_move($item->[1], $item->[0]);
	}
}

sub find_mediafile {
	my %opts = @_;

	$opts{type} // LOGDIE("find_mediafile w/o type");

	if ('enclosure' eq $opts{type}) {
		if ($opts{part}) {
			return $STORAGE->get_processed_path($opts{part});
		} else {
			return $STORAGE->get_enclosure_path($opts{enclosure_no});
		}
	} elsif ('randommedia' eq $opts{type}) {
		return notaint(CONFIG->{storage}{randommedia} . "/$opts{file}");
	} else {
		LOGCONFESS("Uknown media file type: $opts{type}");
	}
}

sub get_one_random {
	# FIXME: Encapsulation violation. Possibly unexpected behavior
	#        depending on if mark is passed. Refactor.
	#
	# FIXME: Even worse now with Storage.
	my %opts        = @_;
	my $random_info = $opts{randoms}
		or LOGCONFESS "Caller failed to pass randoms";
	my $mark       = $opts{mark};
	my $noterandom = $opts{note};
	my $p_no       = $opts{playlist};
	my $p_pos      = $opts{position};

	# First see if we can use a random item feed; if not, we fall back
	# to RandomMedia.
gor_try_feed: {
		last gor_try_feed unless defined $mark;
		last gor_try_feed if rand() >= CONFIG->{playlist}{randomfeedratio};
		last gor_try_feed
			unless my ($enc_no, $enc_file) = $DB->selectrow_array(<<QUERY);
SELECT enclosure_no, enclosure_file
  FROM valids
  WHERE feed_is_music = 1
  ORDER BY random()
  LIMIT 1
QUERY
		my $oldpath = $STORAGE->get_enclosure_path($enc_no);
		$mark->execute($p_no, $p_pos, $enc_no);
		my $newpath = $STORAGE->get_enclosure_path($enc_no);
		TRACE("Random music feed paths: $oldpath -> $newpath");
		return [$newpath, $oldpath];
	}

	# We've fallen back to RandomMedia. Pick a random weight less than
	# the total, then find the item with a binary search.
	my $target  = int rand($random_info->{total_weight});
	my $randoms = $random_info->{randoms};
	my ($low, $high) = (0, $#$randoms);

	# lacking a better guess, let's start our search assuming equal
	# weights. Or at least no bias towards one side of the array. This
	# is a performance assumption, not correctness.
	#
	# XXX: We wind up with maximum probes when our initial guess is
	#      off by one. Not a huge issue, but silly, especially since
	#      that's the most common case!
	my $i = int ($high * $target/$random_info->{total_weight});
	while (1) {
		TRACE("bin search: i=$i, low=$low, high=$high");
		my $item = $randoms->[$i]
			or LOGCONFESS("Binary search bug - no item");
		if ($target > $item->{range_high}) {
			$low = $i + 1;
			$i = $low+int(($high-$low)/2);
		} elsif ($target < $item->{range_low}) {
			$high = $i - 1;
			$i = $high-int(($high-$low)/2);
		} else {
			$noterandom->execute($item->{random_no}, $p_no, $p_pos) if $noterandom;
			return [
				CONFIG->{storage}{randommedia} . '/' . $item->{random_file},
				undef
			];
		}
	}

	LOGCONFESS("Unreachable code reached");
}

sub announce {
	my ($event, $p_no, $p_so, $subs) = @_;

	$event = lc $event;
	exists CONFIG->{speech}{message}{$event}
		or LOGDIE("Tried to announce unconfigured message $event");

	my $msg = CONFIG->{speech}{message}{$event};
	TRACE("Message for $event: $msg; doing subs");

	$msg =~ s/__(.+?)__/$subs->{lc $1}/ge;

	my $tmp = speak($msg);
	my ($s_no, $s_path) = $STORAGE->save_speech_temp(
		temp        => $tmp,
		event       => $event,
		text        => $msg,
		playlist_no => $p_no,
		playlist_so => $p_so,
	);

	return $s_path;
}

sub speak {
	my ($what) = @_;

	my $tmp_wav = $STORAGE->new_speech_temp('.wav');

	TRACE("Speaking $what to $tmp_wav");

	CONFIG->{speech}{engine} =~ /^festival$/i
		or LOGDIE("Festival is the only supported TTS engine, sorry.");

	my $voice = CONFIG->{speech}{voice};
	$voice =~ /^\(?(?:voice_)?([a-z_]+)\)?$/
		or LOGDIE("Invalid voice syntax: $voice");
	$voice = "(voice_$voice)";

	my $dBFS = CONFIG->{speech}{volume};
	$dBFS =~ /^-?(\d+)(?:dbfs)?$/i
		or LOGDIE("Invalid volume: $dBFS");
	$dBFS = "-${1}dBFS";

	TRACE("Invoking festival w/ voice $voice");
	run3 [qw(text2wave -eval), $voice, qw(-f 44100 -o), $tmp_wav], \$what
		or LOGDIE("text2wave failed: $! $?");

	TRACE("Normalizing output to $dBFS");
	run3 [qw(normalize-audio -q -a), $dBFS, $tmp_wav]
		or LOGDIE("normalize-audio failed: $! $?");

	# TODO: When add processing, make this generic.
	my $format = CONFIG->{speech}{format};
	if ($format eq 'wav') {
		return $tmp_wav
	} elsif ($format eq 'mp3') {
		my $tmp_mp3 = $STORAGE->new_speech_temp('.mp3');
		TRACE("Encoding mp3");
		run3 [qw(lame --quiet --preset medium), $tmp_wav, $tmp_mp3]
			or LOGDIE("lame failed: $! $?");
		$STORAGE->discard_speech_temp($tmp_wav);
		return $tmp_mp3;
	} elsif ($format eq 'mp3-cbr') {
		my $tmp_mp3 = $STORAGE->new_speech_temp('.mp3');
		TRACE("Encoding mp3");
		run3 [qw(lame --quiet --preset cbr 64), $tmp_wav, $tmp_mp3]
			or LOGDIE("lame failed: $! $?");
		$STORAGE->discard_speech_temp($tmp_wav);
		return $tmp_mp3;
	} elsif ($format eq 'ogg') {
		my $tmp_ogg = $STORAGE->new_speech_temp('.ogg');
		TRACE("Encoding ogg");
		run3 [qw(oggenc -Q -q0 -o), $tmp_ogg, $tmp_wav]
			or LOGDIE("oggenc failed: $! $?");
		$STORAGE->discard_speech_temp($tmp_wav);
		return $tmp_ogg;
	} else {
		LOGDIE("Uknown format $format")
	}

	LOGDIE("Unreachable code reached");
}

sub playlist_valid_where {
	my ($cur_files, $cur_time, $last_feed, $consec, $bans) = @_;

	my $not_in;
	if ($consec >= CONFIG->{playlist}{maximumconsecutive}) {
		$not_in = join(q{,}, $last_feed, @$bans);
	} else {
		$not_in = join(q{,}, @$bans);
	}
	$not_in = ('' ne $not_in) ? "feed_no NOT IN ($not_in)" : '1';

	my $time_constraint = 1;
	if ($cur_files >= CONFIG->{playlist}{minimumfiles}) {
		my $mx = CONFIG->{playlist}{maximumduration} - $cur_time;
		$time_constraint = "enclosure_time <= $mx";
	};

	return "$not_in AND $time_constraint AND feed_is_music = 0";
}

sub find_random_items {
	wantarray and LOGCONFESS("find_random_items no longer returns an array");

	my $random_info = {
		randoms      => [],
		disabled     => [],
		total_weight => 0,
		# note that total_weight will be 1 more than the greatest
		# range_high, but that's OK because 0 ≤ (rand X) < X
	};

	TRACE("Finding random items");
	my $randommedia = notaint(CONFIG->{storage}{randommedia});
	find({
			wanted => sub {
				unless (-f -r $File::Find::fullname) {
					-d $File::Find::fullname
						or WARN("$File::Find::fullname is not -f and -r");
					return;
				}
				(my $relname = $File::Find::name) =~ s!^\Q$randommedia/\E!!
					or LOGCONFESS("Couldn't strip RandomMedia from $File::Find::name");
				my $dat = $DB->find_or_add_random($relname);

				# range_low and range_high are so we can do a binary
				# search to find the right item. Strictly speaking, one
				# or the other is superfluous.
				#
				# We skip weight-0 items because they'd otherwise wind
				# up with a weird range_high < range_low. Maybe that'd
				# work, but easier to just prohibit it. Put them in
				# disabled instead so they can still be listed.
				#
				# Note the DB has a constraint to force ≥ 0. So
				# negative should never happen, but consider it disabled
				# just in case.
				if ($dat->{random_weight} > 0) {
					$dat->{range_low} = $random_info->{total_weight};
					$random_info->{total_weight} += $dat->{random_weight};
					$dat->{range_high} = $random_info->{total_weight} - 1;
					push @{$random_info->{randoms}}, $dat;
				} else {
					push @{$random_info->{disabled}}, $dat;
				}
			},
			follow  => 1,
			untaint => 1,
		},
		$randommedia);

	DEBUG('Found ', scalar(@{$random_info->{randoms}}),
	      ' (+', scalar(@{$random_info->{disabled}}),
	      " disabled) random items, total weight $random_info->{total_weight}.");

	return $random_info;
}

sub archive {
	local $_;
	if (0 == @ARGV) {
		ERROR("No playlists specified to archive. Try --help");
		return;
	}

	my $proc_sub
		= CONFIG->{archival}{processed}
		? sub { $STORAGE->archive_processed(@_) }
		: sub { $STORAGE->delete_processed(@_) };
	my $speech_sub
		= CONFIG->{archival}{speech}
		? sub { $STORAGE->archive_speech(@_) }
		: sub { $STORAGE->delete_speech(@_) };

	foreach my $arg (@ARGV) {
		my $p_no;
		if ($arg =~ /^[0-9]+$/) {
			$p_no = 0 + $arg;
		} elsif ($arg =~ /^Playlist ([0-9]+)\.m3u$/) {
			$p_no = 0 + $1;
		} else {
			ERROR("Invalid playlist argument: '$arg'. Stopping!");
			return;
		}

		TRACE("Archiving media for playlist $p_no");
		foreach my $e_no (@{$DB->get_playlist_enclosures($p_no)}) {
			$proc_sub->($e_no);
			$STORAGE->archive_original($e_no);
		}
		$speech_sub->($_) foreach @{$DB->get_playlist_speeches($p_no)};

		TRACE("Archiving playlist $p_no");
		$STORAGE->archive_playlist($p_no);

		# we commit after each archival, because a rollback wouldn't move
		# the files back.
		$DB->commit;

		# get rid of empty dirs; these will die if not empty
		# (indicating a bug of some sort)
		$STORAGE->cleanup_original($p_no);
		$STORAGE->cleanup_processed($p_no);

		INFO("Archived playlist $p_no");
	}
}

sub process {
	local $_;
	my $go = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order )]);

	my $redo = 0;
	$go->getoptions(
		'redo|r' => \$redo,
	) or pod2usage(2);

	my @playlists;
	if (@ARGV) {
		@playlists = map s/^playlist\s*//ir, @ARGV;
	} else {
		LOGDIE("process --redo requires playlist numbers as arguments")
			if $redo;
		@playlists = @{$DB->get_playlist_list(1)};
	}

	my $tmp_maker = sub { $STORAGE->new_processed_temp(shift) };
	my %processors;
	@processors{keys %{CONFIG->{processing}{profile}}}
		= map Podist::Processor->new(NC_temp_maker => $tmp_maker, %$_),
		values %{CONFIG->{processing}{profile}};

	my $pm = Parallel::ForkManager->new(CONFIG->{processing}{parallel});

	# it would definitely be nicer to set this up with a per-job closure
	# per-child, but that's not possible — it races. Especially when
	# using 0 children, which completes (of course) before we set it up
	# the next line of code. So we need a single one for all children.
	$pm->run_on_finish(
		sub {
			my ($pid, $excode, undef, $exsig, $exdump, $data) = @_;
			local $_;
			$STORAGE->start_tracking_temp($_) foreach @{$data->{outfiles}};
			$excode || $exsig
				and
				LOGDIE("Processing child blew up (code $excode, signal $exsig)");

			my $playlist_no = $data->{playlist_no};
			my $info = $data->{enclosure_info};
			my $orig_duration = $info->{enclosure_time};
			my $proc_no  = $DB->add_processed(
				enclosure_no => $info->{enclosure_no},
				playlist_no  => $playlist_no,
				profile      => $info->{feed_proc_profile},
				duration     => $data->{duration},
				cputime      => $data->{cputime},
				pid          => $pid,
				parallel     => CONFIG->{processing}{parallel},
				store        => 'processed'
			);
			TRACE("Got files @{$data->{outfiles}}");
			for (my $i = 0; $i < @{$data->{outfiles}}; ++$i) {
				$STORAGE->save_processed_temp(
					temp         => $data->{outfiles}[$i],
					playlist_no  => $playlist_no,
					playlist_so  => $info->{playlist_so},
					processed_no => $proc_no,
					proc_part_so => $i,
					store        => 'processed',
				);
			}
			INFO(
				"Finished $info->{enclosure_no} in $data->{cputime}s, @{[ $data->{cputime} ? $orig_duration/$data->{cputime} : 'inf ' ]}x"
			);
		},
	);

	foreach my $playlist_no (@playlists) {
		my $enclosures_info = $DB->get_processing_info($playlist_no);
		foreach my $info (@$enclosures_info) {
			if ($info->{processed_no}) {
				if ($redo) {
					$STORAGE->delete_processed($info->{enclosure_no});
					$DB->delete_processed_parts($info->{processed_no});
					$DB->delete_processed($info->{enclosure_no});
				} else {
					TRACE("Skipping already-processed $info->{enclosure_no}");
					next;
				}
			}
			my $profile = $info->{feed_proc_profile};
			exists $processors{$profile}
				or LOGDIE(qq{Feed #$info->{feed_no} ($info->{feed_name}) has unknown profile "$info->{feed_proc_profile}"});

			my $in_path = $STORAGE->get_enclosure_path($info->{enclosure_no});
			my $parent_pid = $$;
			my $child = $pm->start_child(
				sub {
					local $_; # not a child if procs == 0
					srand unless $$ == $parent_pid;
					INFO(
						qq{Processing enclosure $info->{enclosure_no} from Playlist $playlist_no#$info->{playlist_so} in pid $$}
					);
					$STORAGE->start_temp_group("Process $info->{enclosure_no}");
					my $cpu_before = sum(times);
					my $outfiles   = $processors{$profile}->process($in_path);
					my $duration   = sum0(map(get_file_duration($_), @$outfiles));
					my $cpu_after  = sum(times);
					my $cputime    = $cpu_after - $cpu_before;
					$STORAGE->stop_tracking_temp($_) foreach @$outfiles;
					$STORAGE->end_temp_group("Process $info->{enclosure_no}");
					TRACE("Child pid=$$ returning");
					return {
						playlist_no    => $playlist_no,
						enclosure_info => $info,
						outfiles       => $outfiles,
						duration       => $duration,
						cputime        => $cputime,
					};
				});
		}
	}

	$pm->wait_all_children;
}

sub feed {
	my $feed = XML::FeedPP::RSS->new(
		title       => 'Podist RSS Export',
		link        => 'https://github.com/derobert/Podist',
		description => q{RSS export of current playlists in Podist},
		generator   => 'Podist',
		pubDate     => time(),
	);
	my $include = CONFIG->{feed}{include};

	foreach my $enc (@{ $DB->unarchived_playlist_info }) {
		if ('randommedia' eq $enc->{type}) {
			$enc->{role} ne 'intermission' || $include->{intermissions}
				or next;
			$enc->{role} ne 'lead-out' || $include->{leadout}
				or next;
		}
		'speech' ne $enc->{type} || $include->{speech}
			or next;    # TODO: not yet implemented

		my $parts
			= ('enclosure' eq $enc->{type})
			? $DB->get_processed_parts($enc->{enclosure_no})
			: [];

		0 == @$parts || 1 == @$parts
			or LOGDIE("TODO: implement multiple parts from processing");

		my $title = sprintf('[%03i-%02i] %s (%s)',
			$enc->{playlist_no}, $enc->{playlist_so},
			($enc->{article_title} // $enc->{enclosure_file}),
			$enc->{feed_name});
		my @item_extra;
		if (CONFIG->{feed}{fudgedates}) {
			@item_extra
				= (pubDate => $enc->{playlist_no} * 1000 + $enc->{playlist_so});
			push @item_extra,
				description => q{From }
				. strftime('%F %H:%M:%S %Z', localtime $enc->{article_when}) . q{.}
				if defined $enc->{article_when};
		} else {
			@item_extra = (pubDate => $enc->{article_when})
				if defined $enc->{article_when};
		}
		my $item = $feed->add_item(title => $title, @item_extra);
		if ('enclosure' eq $enc->{type}) {
			$item->guid(
				"podist-" . $DB->uuid . '-enclosure-' . $enc->{enclosure_no},
				'false');
		} elsif ('randommedia' eq $enc->{type}) {
			$item->guid(
				"podist-"
					. $DB->uuid
					. "-randommedia-$enc->{enclosure_no}-$enc->{playlist_no}-$enc->{playlist_so}",
				'false'
			);
		} else {
			LOGCONFESS("Unknown item type: $enc->{type}.");
		}
		my $file = find_mediafile(
			type => $enc->{type},
			file => $enc->{enclosure_file},
			enclosure_no => $enc->{enclosure_no},
			part => $parts->[0],
		);
		my $mime;
		$file =~ /\.(\S{3,4})$/
			and $mime = $MIME_MAP{lc $1};
		my $size = -s $file;
		$item->set('source@url', $enc->{feed_url}) if defined $enc->{feed_url};
		my $urlextra
			= ($enc->{type} eq 'randommedia')
			? "?$enc->{playlist_no}-$enc->{playlist_so}"
			: q{};
		my $urlpath = join('/', map(uri_escape($_), split('/', File::Spec->abs2rel($file, CONFIG->{storage}{playlists}))));
		$item->set('enclosure@url', CONFIG->{feed}{baseurl} . $urlpath . $urlextra );
		$item->set('enclosure@length', $size);
		$item->set('enclosure@type', $mime) if defined $mime;
	}

	write_file(CONFIG->{storage}{playlists} . '/feed.xml', $feed->to_string);
	INFO("Exported feed");
}

sub notaint {
	defined $_[0] or return undef;
	$_[0] =~ /^(.+)$/s;
	$1;
}

sub parse_global_opts {
	my ($help, $man, $confdir);
	my $getopt = Getopt::Long::Parser->new(
		config => [qw( gnu_compat require_order bundling)]);
	$getopt->getoptions(
		'help|?'               => \$help,
		'man|manual'           => \$man,
		'conf-dir|confdir|c=s' => \$confdir
	) or pod2usage(2);

	if ($help) {
		pod2usage(
			-exitval => 0,
			-verbose => 99,
			-sections => [ 'SYNOPSIS', 'GLOBAL OPTIONS', 'COMMAND SUMMARY' ],
			-output => \*STDOUT,
		);
	}

	if ($man) {
		pod2usage(
			-exitval => 0,
			-verbose => 2,
			-output => \*STDOUT,
		);
		exit 0;
	}

	return { config_dir => $confdir };
}

sub setup {
	my $confdir = shift // notaint("$ENV{HOME}/.podist");

	-d $confdir
		or mkdir $confdir
		or die "Could not mkdir $confdir: $!";

	# read config and install sub
	my $config
		= Podist::Config->new->read_or_create_config(conf_dir => $confdir)
		or die "Failed to get any config; very malformed config file?";

	{
		# work around "constants from lexical variables potentially
		# modified elsewhere are deprecated" by making it clear this
		# won't be modified.
		my $grumble = $config;
		*CONFIG = sub() { $grumble };
	}

	init_logging();

	# more config setup, but with logging available
	inherit_proc_profiles(CONFIG->{processing}{profile}); # modifies

	# get terminal width
	$TERM_COLS  = 0 + notaint($ENV{COLUMNS} // 0);
	$TERM_LINES = 0 + notaint($ENV{LINES}   // 0);
	if (0 == $TERM_COLS || 0 == $TERM_LINES) {
		TRACE("Getting terminal size via Term::Size::Any");
		my ($c, $l) = Term::Size::Any::chars(*STDOUT);
		$TERM_COLS  ||= $c // 0;
		$TERM_LINES ||= $l // 0;
	}
	if (0 == $TERM_COLS || 0 == $TERM_LINES) {
		WARN(
			"Failed to get terminal size (got ${TERM_COLS}x${TERM_LINES}); defaulting 0s to 80x24."
		);
		$TERM_COLS  ||= 80;
		$TERM_LINES ||= 24;
	}
	TRACE("Terminal size: ${TERM_COLS}x${TERM_LINES}.");

	if (CONFIG->{notyetconfigured}) {
		FATAL(<<ERR);
Podist has not been configured. Please review this configuration file
and set NotYetConfigured to false:
    $confdir/podist.conf
ERR
		exit 1;
	}

	if (CONFIG->{configversion} == 1) {
		FATAL(<<ERR);
Your existing Podist configuration is for Podist 0.3 or before. Podist
version 0.4 and higher require several changes to your existing config
and possibly also requires moving files around. Please review the
UPGRADING file for instructions.
ERR
		exit 1;
	}
	if (CONFIG->{configversion} > $CONFIG_VERSION) {
		FATAL(<<ERR);
Your existing Podist configuration is for a newer version of Podist than
you're currently running. If this is intentional, please review the
UPGRADING (and possibly the git logs) file to see what you might need to
change.
ERR
		exit 1;
	}

	# Untaint the environment
	$ENV{PATH} = notaint($ENV{PATH});

	# setup the DB
	$DB = Podist::Database->new(
		dsn => CONFIG->{database}{dsn},
		username => CONFIG->{database}{username},
		password => CONFIG->{database}{password}
	);

	# set up storage
	$STORAGE = Podist::Storage->new(
		DB => $DB,
		config => CONFIG->{storage},
	);

	return;
}

sub init_logging {
	if (CONFIG->{logging}{simple}) {
		my $level = uc(CONFIG->{logging}{level});
		Log::Log4perl->init(\<<L4P);
log4perl.category = $level, Screen
log4perl.appender.Screen = Log::Log4perl::Appender::ScreenColoredLevels
log4perl.appender.Screen.layout = Log::Log4perl::Layout::PatternLayout::Multiline
log4perl.appender.Screen.layout.ConversionPattern = [%r] %m%n
L4P
	} else {
		Log::Log4perl::init(CONFIG->{logging}{config});
	}
	TRACE("Log4perl configured and hopefully ready.");
}

sub USER_AGENT() {
	state $agent;
	unless ($agent) {
		$agent = LWP::UserAgent->new(
			agent => "Podist/$PODIST_VERSION",
			env_proxy => 1,
			keep_alive => 4, # Some podcasts love redirects
			cookie_jar => { }, # temp only
			ssl_opts => {
				verify_hostname => 1,
				SSL_cipher_list => 'DEFAULT@SECLEVEL=1',
			}
		);

		$agent->default_header(
			Accept => 'application/rss+xml, application/atom+xml, audio/ogg, audio/x-ogg, audio/mpeg, application/rdf+xml;q=0.9, application/xml;q=0.8, text/xml;q=0.8, application/ogg;q=0.8, audio/*;q=0.7, */*;q=0.1'
		);
	}

	return $agent;
}

__END__

=encoding utf8

=head1 NAME

Podist - A podcatcher

=head1 SYNOPSIS

podist [I<global-options>] I<command> [I<command-options>] [I<arguments>]

podist --help

podist --manual

=head1 COMMAND SUMMARY

B<catch> — Find & download new episodes.

B<subscribe> I<name> I<url> — Subcribe to a new feed at I<url> and call
it I<name>.

B<playlist> — Generate a playlist.

B<status> — Show unplayed counts & other statistics.

=head1 GLOBAL OPTIONS

=over

=item B<--conf-dir>

Directory to store the configuration file in. Also the default place to
store the SQLite database.

=item B<--help>

Displays help.

=item B<--man>

Displays the manual page.

=back

=head1 COMMANDS

=head2 B<subscribe> | B<new> | B<add> I<name> I<URL>

Subscribe to a new podcast named Name with feed at URL. URL should be
the RSS or Atom feed. Name is anything you want, but must be unique for
all your subscribed podcasts. Remember to quote Name and URL for your
shell.

=over

=item I<name>

What to call this podcast. Used in messages, status output, etc. Any
string you'd like.

=item I<URL>

URL of the feed. All common formats are accepted (Atom and multiple
versions of RSS).

=back

=head2 B<catch>

Run the podcatcher. The same as fetch, download, and stopwatch (in that
order) below.

=head2 drop

Drop a podcast, including marking don't-use all the unplaylisted
episodes. If you want to just stop adding new episodes instead, see
L<editfeed>'s C<--disable> option instead. (Note: if a episode has been
linked from multiple podcasts, it will still be marked don't use.
Presumably you don't care if a different podcast included an episode of
a podcast you don't want to listen to. This is a rare occurrence anyway.)

Running L<cleanup> after this will move these episodes to the unusable
media directory (which you can move offline or even delete).

=over

=item B<--feed> | B<-f> I<feed_number>

The feed number to drop, which you can get from (among other places)
C<Podist list -f>.

=back

=head2 B<fetch> [ --feeds I<feed_no> ... ] [ --limit I<N> ]

Grabs the subscribed RSS feeds and adds all the enclosures to the
database. Does not actually download the enclosures.

=over

=item B<--feeds> | B<-f> I<feed_number> ...

One of more feeds to fetch. This overrides the default of fetching all
enabled feeds. Note that with this, you can even fetch disabled feeds.

Note that feeds are specified by their feed number, which can be
discovered using the L<C<list --feeds>|/"list"> command.

=item B<--fetch-limit> | B<--new-limit> | B<--limit> | S<B<-l> I<N>>

Override the database-set limit of new items to grab from the feed. This
is useful when something special happens on a feed and you actually do
want to grab those 20 new episodes that were posted.

=back

=head2 B<download>

Downloads enclosures that are in the database (from fetch) but not
yet downloaded.

=head2 B<hash>

Calculates the hash for each downloaded podcast and stores this in
the database. The hash is used to catch duplicates.

=head2 B<originalize>

Finds duplicate podcasts based on their hash, and marks the second
(and third, etc.) copies such that they won't be used.

=head2 B<stopwatch>

Calculates how long each downloaded podcast is, and stores this
information in the database.

=head2 B<playlist>

Builds playlists based on downloaded, stopwatched media in the
database.

=head2 B<archive> Plalist-1 ...

Archives the given playlists. Playlists may be specified either as file
names ("Playlist 625.m3u") or as plain numbers ("625"). At least one
playlist must be specified.

Archiving a playlist means that the files are moved to the archived
playlists directory and the playlist is marked as archived in the
database.

Currently, the only effect on Podist operation is that archived
playlists are not included in the generated feed (feed.xml in the
playlist directory).

=head2 B<process> [ --redo ] [Playlist1...]

Runs configured audio processing. By default, processes all non-archived
playlists and only processes an audio file if there isn't already a
processed version. You can pass one or more playlists to limit
processing to just those playlists.

The B<--redo> option will re-process files even if there is already a
processed version. This can be useful after changing the audio
processing configuration, for example.

=head2 B<feed>

Generates an RSS feed from the non-archived playlists. The feed will be
in the same order as the playlists (so consuming podcatchers should be
instructed to use it in order).

=head2 B<status>

Shows a summary of what's in the database.

=head2 B<history>

Generates a history of how many episodes were present, how many were
unplayed, the total time, and the unplayed time at the time each
playlist was generated. Writes the result to STDOUT in CSV format.

Warning: This query makes the database work. It will peg the CPU for a
few seconds.

Note: the database only stores the article publication date, not the
date each enclosure was added to the database. So that's what we use to
generate the history. In particular, you won't see big jumps from adding
a new podcast with a huge backlog--instead, the episodes will be spread
out based on when they were published. Essentially, this is what history
would have looked like had you always been subscribed to all your
podcasts.

Nitpick: The enclosure_use and article_use flags in the database don't
have timestamps at all. The current values are presumed to apply for all
time. So you won't see big drops if, e.g., you marked a bunch of
enclosures enclosure_use=0 in the database. Note any automatic don't-use
marking by Podist is done during "catch" so is actually for all time.

=head2 B<list> I<options>

Shows various things from the database.

=over

=item B<--feeds> | B<-f>

List the feeds in the database, both enabled and disabled.

=item B<--randoms> | B<-r>

List the random items found on the filesystem, along with their weight
(from the database). Note that the also adds any new random items to the
database.

=item B<--long> | B<-l>

List more details. Currently, for feeds, makes it list all the columns
stored in the database (everything you can edit with C<Podist editfeed>.

=back

=head2 editfeed

    Podist editfeed --feed-no <<feed-number>> <<options>>

Edits the various attributes for a feed stored in the database. Specify
at least one thing to change using the options below; anything you don't
specify remains unchanged.

=over

=item B<--feed-no> | B<-f> I<number>

The feed number (the one displayed by C<Podist list -f>). Required.

=item B<--url> I<URL>

Change the RSS/Atom feed URL. Useful if a podcast changes its feed URL.

=item B<--name> I<NAME>

Change the feed name. This is used for display purposes in various
places, such as Podist output and also, e.g., in generated feeds from
C<Podist feed>.

=item B<--disable> | B<--enable>

Disable or enable the feed. A disabled feed is not fetched, but already
fetched episodes remain (and will still be used in future playlists).
Obviously an error to specify both of these options (but neither is
fine, which, like all the rest of the options, leaves it in its current
state).

Note that you can force Podist to fetch a disabled feed by using
C<Podist fetch> or C<Podist catch>'s C<-f> option.

Default: enabled.

=item B<--ordered> | B<--no-ordered>

Ordered feeds must be inserted into a playlist with their episodes in
order. "No-ordered" feeds can have their episodes inserted in any order
(which can help satisfy playlist constraints if the episodes are
different lenghts). The default for newly created feeds is ordered.

=item B<--all-audio> | B<--no-all-audio>

If a feed is marked all audio then a warning will be raised (in the
Podist log, typically written to the terminal) if an item doesn't have
an enclosure. Otherwise, no warning will be raised. Default: all audio.

=item B<--is-music> | B<--no-is-music>

If a feed is marked as music, then it will be used for intermissions in
place of C<RandomMedia> some of the time (controlled by the
C<RandomFeedRatio> configuration option). It will not be played as a
normal episode. Default: is not music.

=item B<--limit-amount> I<LIMIT>

=item B<--limit-period> I<DURATION>

These two together specify the maximum number of new items that will be
accepted from a feed. The goal is to bail out if, e.g., a podcast messes
up their feed causing many/all episodes to appear new. The way it works
is Podist checks how many new articles Podist has fetched in the last
I<DURATION>. (Only when Podist fetched them matters; the article dates
specified in the feed are ignored.) It then subtracts that from
I<LIMIT>. That's the maximum number of new articles Podist will accept;
if there are more than that, Podist will not add I<any of them>. If that
maximum is zero (or less), then the fetch is skipped entirely.

You can override I<LIMIT> on a per-fetch basis with C<Podist
fetch>/C<Podist catch>'s C<--fetch-limit> option.

I<DURATION> is specified in seconds, or alternatively you can specify a
unit with a suffix: B<s>econds, B<m>inutes, B<h>ours, B<d>ays, B<w>eeks.
These are aliases for a number of seconds; things like some weeks being
an hour shorter or longer due to daylight saving time changes are
ignored. So C<1w> means 604,800 seconds.

Default: 3 episodes per week.

=item B<--proc-profile> I<PROFILE>

Set processing profile for playlist items from this feed. The profiles
control the various processing options (currently things like the target
volume level, if any range limiting is applied, and if the audio is
stretched/sped up) and are defined in the config file.

=back

=head2 editrandom

    Podist editrandom --random-no <<random-number>> <<options>>

Edits the various attributes for a random media stored in the database.
Specify at least one thing to change using the options below; anything
you don't specify remains unchanged.

=over

=item B<--random-no> | B<-r> I<number>

The random number (the one displayed by C<Podist list -r>). Required.

=item B<--weight> I<WEIGHT>

Change the weight of the random item (how frequently its chosen). Higher
numbers are chosen more frequently; double the number and you double the
chance. A weight of 0 means the random is disabled (will never be
picked). Default: 1000.

=item B<--name> I<NAME>

Change the name of the random item. This isn't currently used for
anything except C<Podist list -r>. Default: Based on the file name.

=back

Note there is no way to change the file name. That's how Podist tracks
the random item; changing it would make it a different random item (and
Podist would just insert a new row if the file still exists). If the
file no longer exists, Podist will just ignore the random item entry in
the database.

=head2 B<fsck>

Do various consistency checks. So far, looks for enclosures that are (a)
supposed to be used and (b) are not associated with an article
("orphaned"). This is a problem because without an article, they can't
be used.

Eventually, this will be extended to do thorough checks, including
checking for missing downloaded files and maybe even confirming hashes.

=head2 B<cleanup>

Do various once-in-a-while cleanup tasks, like moving enclosures
that we're not going to use (duplicates, manually set to not use
in database, etc.) to the unusable folder.
